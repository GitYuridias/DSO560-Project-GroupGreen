{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "NLP_project_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgJTTUmQFuLX",
        "colab_type": "code",
        "outputId": "89a33625-e872-4c74-814a-5a0d4fd69119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls8WfAo2FYfY",
        "colab_type": "code",
        "outputId": "6ca24e81-e5f9-445b-db7b-74c26f2ce7b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNFyvgOENV1P",
        "colab_type": "code",
        "outputId": "0941ae19-058e-4d9e-cfbc-9498d7a926e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "start = pd.datetime.now()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaUpQFTaLqDj",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EKGPE67Low8",
        "colab_type": "code",
        "outputId": "36fbe931-777a-40ec-bf20-135dfebc5b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load full_data from the dataset of SQL\n",
        "df_SQL = pd.read_csv('/content/drive/My Drive/NLP/full_data.csv')\n",
        "df_SQL.drop(columns=['created_at', 'updated_at', 'deleted_at', 'bc_product_id'], inplace=True)\n",
        "for columns in df_SQL.columns:\n",
        "    df_SQL[columns] = df_SQL[columns].str.lower() \n",
        "df_SQL.drop_duplicates(subset= ['product_id'], keep = 'first', inplace=True)\n",
        "df_SQL.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48072, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oeIzLHaLoq2",
        "colab_type": "code",
        "outputId": "76e4bff6-bf8b-444e-a203-a065d6a5fa09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load tagged_product_attributes from the dataset of SQL\n",
        "tag_SQL = pd.read_csv('/content/drive/My Drive/NLP/tagged_product_attributes.csv')\n",
        "\n",
        "for columns in tag_SQL.columns:\n",
        "    tag_SQL[columns] = tag_SQL[columns].str.lower() \n",
        "    \n",
        "remove = [' ', '_', '(', ')', '-', ',', '&', '\"', '\"', '/']\n",
        "for i in remove:\n",
        "    tag_SQL['attribute_name'] = tag_SQL['attribute_name'].str.replace(i, '')\n",
        "    tag_SQL['attribute_value'] = tag_SQL['attribute_value'].str.replace(i, '')\n",
        "\n",
        "tag_SQL.drop(columns='file', inplace=True)\n",
        "tag_SQL.drop_duplicates(keep='first', inplace=True) #only removed duplicates that have same data in all of the columns\n",
        "tag_SQL.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97950, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_y8GfUXLokw",
        "colab_type": "code",
        "outputId": "99ead2f4-c345-41a1-b772-8f6682e9e3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# inner join\n",
        "df_join = pd.merge(df_SQL, tag_SQL.drop(columns='product_color_id'), how='inner', on='product_id')\n",
        "focus_attribute = ['style', 'occasion', 'category', 'fit', 'embellishment']\n",
        "df_messy = df_join[df_join.attribute_name.isin(focus_attribute)].reset_index(drop=True)\n",
        "\n",
        "for att in focus_attribute:\n",
        "    df_messy[att] = np.where(df_messy.attribute_name==att, df_messy.attribute_value, None)\n",
        "df_messy.replace(np.nan, '', regex=True, inplace=True)\n",
        "df_messy.drop_duplicates(inplace=True)\n",
        "df_messy.reset_index(inplace=True)\n",
        "df_messy.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26944, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7NgQr2iPga1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lemmatize\n",
        "def lemmatize(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = text.split()\n",
        "    stemmed_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(stemmed_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up8odUXXPd1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocess\n",
        "def preprocessing(data):\n",
        "    '''inputdata should have 5 columns: brand, product_full_name, description, brand_category, and details'''\n",
        "    \n",
        "    data.replace(np.nan, '', regex=True, inplace=True)\n",
        "\n",
        "    # regex cleaning\n",
        "    for i in range(0,len(data)):\n",
        "        text = data.loc[i,'description']\n",
        "        text = re.sub(r'([0-9]+)', '', text)\n",
        "        text = re.sub(r'\\b(jeans|pants|skirt|shorts|leggings|trousers)\\b', 'bottom', text)\n",
        "        text = re.sub(r'\\b(sweater|shirt|jacket|tshirt|coat|blazer|cardigan|hoodie)\\b', 'top', text)\n",
        "        text = re.sub(r'\\b(sneakers|boots|flats|heels|slippers|sandals)\\b', 'shoe', text)\n",
        "        text = re.sub(r'\\b(dress|one piece|jumpsuit)\\b', 'onepiece', text)  \n",
        "        data.loc[i,'description'] = text\n",
        "    \n",
        "    data['product_full_name'] = data['product_full_name'].str.replace(r'([0-9]+)','')\n",
        "    data['details'] = data['details'].str.replace(r'([0-9]+)','')\n",
        "    data['brand_category'] = data['brand_category'].str.replace(r'([0-9]+)','')\n",
        "\n",
        "    # define stopwords\n",
        "    stopwords_gensim = list(STOPWORDS)\n",
        "    stopwords_NLTK = list(stopwords.words(\"english\"))\n",
        "    stopwords_combined = list(set(stopwords_gensim+stopwords_NLTK)) #to remove duplicates\n",
        "    negatives = ['not','nor','no','neither', 'never', 'bottom', 'top'] #took out the negative words for a more accurate analysis\n",
        "    stopwords_combined = list(filter(lambda x: x not in negatives, stopwords_combined))\n",
        "    stopwords_combined.sort()\n",
        "    stopwords_expression = '|'.join(stopwords_combined)\n",
        "    stopwords_pattern = f'({stopwords_expression})'\n",
        "\n",
        "    # remove stopwords & lemmatization\n",
        "    for i in ['product_full_name', 'description', 'brand_category', 'details']:\n",
        "        data[i] = data[i].astype(str)\n",
        "        data[i] = data[i].str.replace(r'[^\\w\\s]',' ')\n",
        "        data[i] = data[i].str.replace(r'\\n', ' ')\n",
        "        data[i] = data[i].str.replace(rf'\\b{stopwords_pattern}\\b','')\n",
        "        data[i] = data[i].apply(lemmatize)\n",
        "\n",
        "    # combine features into one text variable\n",
        "    data['vars'] = data['brand']+' '+data['product_full_name']+' '+data['description']+' '+data['brand_category']+' '+data['details']\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZOJaTYiLoeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = preprocessing(df_messy)\n",
        "df.drop(columns=['mpn','brand_canonical_url','labels'], inplace=True)\n",
        "#df.to_csv('/content/drive/My Drive/NLP/df.csv')\n",
        "#df = pd.read_csv('/content/drive/My Drive/NLP/df.csv', index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsSqgAkFSbft",
        "colab_type": "code",
        "outputId": "cfcbb5dc-ab50-42e9-abca-a141280f6aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26944, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2zztes5TGQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PovvCwVbZfH2",
        "colab_type": "code",
        "outputId": "8b59b8cc-c909-4043-8756-3b0f0362ed10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "df['category'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan, 'bottom', 'top', 'sweater', 'onepiece', 'blazerscoatsjackets',\n",
              "       'shoe', 'accessory', 'sweatshirthoodie'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfzfpBp0QcY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adjust categories to the list in the excel\n",
        "df['category'] = np.where(df['category']=='sweater', 'top', np.where(df['category']=='blazerscoatsjackets', 'top', np.where(df['category']=='sweatshirthoodie', 'top', df['category'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA0cUjEjFYf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = ['brand','product_full_name','description','brand_category','details']\n",
        "for col in cols:\n",
        "    df[col].fillna('',inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUR4XR8QWYag",
        "colab_type": "code",
        "outputId": "d4ce8176-f941-450b-8b52-7ab299daa07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26944, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-71d3DFYf8",
        "colab_type": "code",
        "outputId": "ffe2673c-435e-47f4-9d3e-98fd47a32d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "index                    0\n",
              "product_id               0\n",
              "brand                    0\n",
              "product_full_name        0\n",
              "description              0\n",
              "brand_category           0\n",
              "details                  0\n",
              "attribute_name           0\n",
              "attribute_value          0\n",
              "style                16430\n",
              "occasion             17890\n",
              "category             22968\n",
              "fit                  23904\n",
              "embellishment        26584\n",
              "vars                     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSTxlReUFYgf",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSPsAAiAFYgg",
        "colab_type": "text"
      },
      "source": [
        "### Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zxqpFRyFYgh",
        "colab_type": "code",
        "outputId": "c8dd09ec-cc6a-4fdf-ec18-f7736463fec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_WkQG51FYgl",
        "colab_type": "code",
        "outputId": "fc533c45-bdae-46ad-f0d3-5a7a42d3c26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# train word2vec using all 5 columns\n",
        "cols = ['brand','product_full_name','description','brand_category','details']\n",
        "embedding_size=100\n",
        "docs=[]\n",
        "for col in cols:\n",
        "    docs += [word_tokenize(i) for i in df[col]] \n",
        "wordvec = Word2Vec(docs, size=embedding_size, min_count=1)\n",
        "print(wordvec)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=6813, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKfS8QbcGccR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = list(wordvec.wv.vocab)\n",
        "wordvec_num = [wordvec.wv[i] for i in vocab]\n",
        "wordvec_dict = dict(zip(vocab, wordvec_num))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3lADDmzFYgy",
        "colab_type": "text"
      },
      "source": [
        "# Deep NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otp4H4daFYg2",
        "colab_type": "code",
        "outputId": "f171a826-1dc8-456f-8a79-c33d44fd1b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from random import randint\n",
        "from numpy import array, argmax, asarray, zeros\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.recurrent import SimpleRNN\n",
        "from keras.layers import Flatten, Masking\n",
        "from keras import regularizers\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, History\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vn0bVICdzNXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare inputs for NN\n",
        "def preparemodel(data, embedding_size):\n",
        "    tokenizer = Tokenizer(num_words=None, oov_token=\"UNKNOWN_TOKEN\")\n",
        "    tokenizer.fit_on_texts(data['vars'])\n",
        "    encoded_docs = tokenizer.texts_to_sequences(data['vars'])\n",
        "\n",
        "    max_sequence_len = 180\n",
        "    # Used the code below to find out the max_sequence_len on the df (173)\n",
        "    #max_sequence_len = 0\n",
        "    #for i in encoded_docs:\n",
        "        #if len(i) > max_sequence_len:\n",
        "            #max_sequence_len=len(i)\n",
        "\n",
        "    padded_docs = pad_sequences(encoded_docs, maxlen=max_sequence_len, padding='post')\n",
        "    \n",
        "    vocab_size = 6900\n",
        "    # Used the code below to find out the max vocab_size on the df (6807)\n",
        "    #vocab_size = len(tokenizer.word_index)+1\n",
        "    \n",
        "    embedding_matrix = zeros((vocab_size, embedding_size))\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        embedding_vector = wordvec_dict.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    \n",
        "    return padded_docs, vocab_size, max_sequence_len, embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PePhWt00d5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# deep nn with softmax\n",
        "def deepnn_multiclass(X, y, vocab_size, embedding_size, embedding_matrix, max_sequence_len, node=10, val_data:tuple=None, val_split=0):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embedding_size, weights=[embedding_matrix], input_length=max_sequence_len, trainable=False))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(node, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
        "    model.add(Dense(len(y[0]), activation='softmax'))\n",
        "    \n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(X, y, validation_data=val_data, validation_split=val_split, epochs=30, verbose=0, callbacks= [EarlyStopping(patience = 5), ModelCheckpoint(filepath = \"/content/drive/My Drive/NLP/weights.hdf5\", save_best_only= True), History()])\n",
        "    model_new = tf.keras.models.load_model(filepath = \"/content/drive/My Drive/NLP/weights.hdf5\")\n",
        "    return model_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhROg45o5Zat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# deep nn with sigmoid\n",
        "def deepnn_binary(X, y, vocab_size, embedding_size, embedding_matrix, max_sequence_len, node=10, val_data:tuple=None, val_split=0):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embedding_size, weights=[embedding_matrix], input_length=max_sequence_len, trainable=False))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(node, kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(X, y, validation_data=val_data, validation_split=val_split, epochs=30, verbose=0, callbacks= [EarlyStopping(patience = 5), ModelCheckpoint(filepath = \"/content/drive/My Drive/NLP/weights.hdf5\", save_best_only= True), History()])\n",
        "    model_new = tf.keras.models.load_model(filepath = \"/content/drive/My Drive/NLP/weights.hdf5\")\n",
        "    return model_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7JV7lXszZDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cross validation for multiclass attributes\n",
        "def modelcv_multiclass(labelname, n_splits=5):\n",
        "    data = df.dropna(subset=[labelname])\n",
        "    encoder = LabelEncoder()\n",
        "    labels = to_categorical(encoder.fit_transform(data[labelname]))\n",
        "    \n",
        "    temp = preparemodel(data, embedding_size)\n",
        "    padded_docs, vocab_size, max_sequence_len, embedding_matrix = temp[0], temp[1], temp[2], temp[3]\n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle = True)\n",
        "    kf.get_n_splits(padded_docs)\n",
        "\n",
        "    maximum, node_final, train_acc_final, test_acc_final = 0,0,0,0\n",
        "    for node in [10,20,30]:\n",
        "        train_acc = 0\n",
        "        test_acc = 0\n",
        "        for train_index, test_index in kf.split(padded_docs):\n",
        "            X_train, X_test, y_train, y_test = padded_docs[train_index], padded_docs[test_index], labels[train_index], labels[test_index]\n",
        "            model = deepnn_multiclass(X_train, y_train, vocab_size, embedding_size, embedding_matrix, max_sequence_len, node=node, val_data=(X_test,y_test))\n",
        "            loss_train, accuracy_train = model.evaluate(X_train, y_train, verbose=0)\n",
        "            loss_test, accuracy_test = model.evaluate(X_test, y_test, verbose=0)\n",
        "            train_acc += accuracy_train\n",
        "            test_acc += accuracy_test\n",
        "        if maximum < test_acc/n_splits:\n",
        "            maximum = test_acc/n_splits\n",
        "            node_final = node\n",
        "            train_acc_final = train_acc/n_splits\n",
        "            test_acc_final = test_acc/n_splits\n",
        "          \n",
        "    return node_final, train_acc_final, test_acc_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2acmwAeILAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cross validation for binary attributes\n",
        "def modelcv_binary(labelname, uniquename, n_splits=5):\n",
        "    data = df.dropna(subset=[labelname]).copy()\n",
        "    data['temp'] = np.where(data[labelname]==uniquename, 0, 1)\n",
        "    data.sort_values(by=['product_id','temp'], inplace=True)\n",
        "    data.drop_duplicates(subset=['product_id'], keep='first', inplace=True)\n",
        "    data.reset_index(drop=True, inplace=True)\n",
        "    labels = np.where(data[labelname]==uniquename,1,0)\n",
        "\n",
        "    temp = preparemodel(data, embedding_size)\n",
        "    padded_docs, vocab_size, max_sequence_len, embedding_matrix = temp[0], temp[1], temp[2], temp[3] \n",
        "\n",
        "    kf = KFold(n_splits=n_splits, shuffle = True)\n",
        "    kf.get_n_splits(padded_docs)\n",
        "\n",
        "    maximum, node_final, train_acc_final, test_acc_final = 0,0,0,0\n",
        "    for node in [10,20,30]:\n",
        "        train_acc = 0\n",
        "        test_acc = 0\n",
        "        for train_index, test_index in kf.split(padded_docs):\n",
        "            X_train, X_test, y_train, y_test = padded_docs[train_index], padded_docs[test_index], labels[train_index], labels[test_index]\n",
        "            model = deepnn_binary(X_train, y_train, vocab_size, embedding_size, embedding_matrix, max_sequence_len, node=node, val_data=(X_test,y_test))\n",
        "            loss_train, accuracy_train = model.evaluate(X_train, y_train, verbose=0)\n",
        "            loss_test, accuracy_test = model.evaluate(X_test, y_test, verbose=0)\n",
        "            train_acc += accuracy_train\n",
        "            test_acc += accuracy_test\n",
        "        if maximum < test_acc/n_splits:\n",
        "            maximum = test_acc/n_splits\n",
        "            node_final = node\n",
        "            train_acc_final = train_acc/n_splits\n",
        "            test_acc_final = test_acc/n_splits\n",
        "          \n",
        "    return node_final, train_acc_final, test_acc_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSWgXnYms7iA",
        "colab_type": "text"
      },
      "source": [
        "### Cross Validation \n",
        "- hyperparameter: number of nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0QLPmeQe1bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target, best_node, train_accuracy, test_accuracy = [],[],[],[]\n",
        "for col in ['category','fit']:\n",
        "    temp = modelcv_multiclass(col)\n",
        "    target.append(col)\n",
        "    best_node.append(temp[0])\n",
        "    train_accuracy.append(temp[1])\n",
        "    test_accuracy.append(temp[2])\n",
        "result_multiclass = pd.DataFrame(zip(target,best_node,train_accuracy,test_accuracy), columns=['target','best_node','train_accuracy','test_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wr0kt8YjLmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target, best_node, train_accuracy, test_accuracy = [],[],[],[]\n",
        "for col in ['style','occasion','embellishment']:\n",
        "    for name in df.dropna(subset=[col])[col].unique():\n",
        "        temp = modelcv_binary(col, name)\n",
        "        target.append(col+'-'+name)\n",
        "        best_node.append(temp[0])\n",
        "        train_accuracy.append(temp[1])\n",
        "        test_accuracy.append(temp[2])\n",
        "result_binary = pd.DataFrame(zip(target,best_node,train_accuracy,test_accuracy), columns=['target','best_node','train_accuracy','test_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfh-t2Nrr0QY",
        "colab_type": "code",
        "outputId": "aa5cdffb-66c0-4894-9590-3d1018732138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "# Accuracy table on the category\n",
        "result_multiclass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>best_node</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>test_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>category</td>\n",
              "      <td>10</td>\n",
              "      <td>0.997107</td>\n",
              "      <td>0.942404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fit</td>\n",
              "      <td>30</td>\n",
              "      <td>0.645806</td>\n",
              "      <td>0.491118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     target  best_node  train_accuracy  test_accuracy\n",
              "0  category         10        0.997107       0.942404\n",
              "1       fit         30        0.645806       0.491118"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orlr_-NZjK4V",
        "colab_type": "code",
        "outputId": "6926209b-3a40-4ae2-d5b6-9a4660533670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Accuracy table on the style, occasion, embellishment\n",
        "result_binary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>best_node</th>\n",
              "      <th>train_accuracy</th>\n",
              "      <th>test_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>style-modern</td>\n",
              "      <td>20</td>\n",
              "      <td>0.789839</td>\n",
              "      <td>0.694330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>style-businesscasual</td>\n",
              "      <td>30</td>\n",
              "      <td>0.852973</td>\n",
              "      <td>0.756894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>style-classic</td>\n",
              "      <td>20</td>\n",
              "      <td>0.739658</td>\n",
              "      <td>0.653721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>style-casual</td>\n",
              "      <td>20</td>\n",
              "      <td>0.878381</td>\n",
              "      <td>0.755874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>style-androgynous</td>\n",
              "      <td>20</td>\n",
              "      <td>0.867531</td>\n",
              "      <td>0.823800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>style-boho</td>\n",
              "      <td>20</td>\n",
              "      <td>0.897344</td>\n",
              "      <td>0.880491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>style-retro</td>\n",
              "      <td>30</td>\n",
              "      <td>0.947524</td>\n",
              "      <td>0.943565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>style-edgy</td>\n",
              "      <td>30</td>\n",
              "      <td>0.831142</td>\n",
              "      <td>0.799285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>style-glam</td>\n",
              "      <td>20</td>\n",
              "      <td>0.902004</td>\n",
              "      <td>0.891219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>style-romantic</td>\n",
              "      <td>10</td>\n",
              "      <td>0.869318</td>\n",
              "      <td>0.857001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>style-athleisure</td>\n",
              "      <td>10</td>\n",
              "      <td>0.986977</td>\n",
              "      <td>0.952246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>occasion-work</td>\n",
              "      <td>30</td>\n",
              "      <td>0.863631</td>\n",
              "      <td>0.737864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>occasion-daytonight</td>\n",
              "      <td>10</td>\n",
              "      <td>0.761947</td>\n",
              "      <td>0.740918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>occasion-weekend</td>\n",
              "      <td>20</td>\n",
              "      <td>0.809081</td>\n",
              "      <td>0.772094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>occasion-vacation</td>\n",
              "      <td>30</td>\n",
              "      <td>0.879151</td>\n",
              "      <td>0.844406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>occasion-nightout</td>\n",
              "      <td>20</td>\n",
              "      <td>0.832459</td>\n",
              "      <td>0.776697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>occasion-coldweather</td>\n",
              "      <td>30</td>\n",
              "      <td>0.954713</td>\n",
              "      <td>0.934083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>occasion-workout</td>\n",
              "      <td>20</td>\n",
              "      <td>0.983139</td>\n",
              "      <td>0.967550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>embellishment-crystals</td>\n",
              "      <td>30</td>\n",
              "      <td>0.998479</td>\n",
              "      <td>0.966620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>embellishment-mesh</td>\n",
              "      <td>30</td>\n",
              "      <td>0.992395</td>\n",
              "      <td>0.936177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>embellishment-lace</td>\n",
              "      <td>30</td>\n",
              "      <td>0.993156</td>\n",
              "      <td>0.933054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>embellishment-trim</td>\n",
              "      <td>20</td>\n",
              "      <td>0.937677</td>\n",
              "      <td>0.884569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>embellishment-ruffles</td>\n",
              "      <td>10</td>\n",
              "      <td>0.992395</td>\n",
              "      <td>0.884569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>embellishment-fringe</td>\n",
              "      <td>20</td>\n",
              "      <td>0.979491</td>\n",
              "      <td>0.960466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>embellishment-studs</td>\n",
              "      <td>20</td>\n",
              "      <td>0.984791</td>\n",
              "      <td>0.869371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>embellishment-embroidery</td>\n",
              "      <td>20</td>\n",
              "      <td>0.947598</td>\n",
              "      <td>0.884429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>embellishment-buckles</td>\n",
              "      <td>10</td>\n",
              "      <td>0.964302</td>\n",
              "      <td>0.926993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>embellishment-rhinestone</td>\n",
              "      <td>10</td>\n",
              "      <td>0.997719</td>\n",
              "      <td>0.969604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>embellishment-sequins</td>\n",
              "      <td>20</td>\n",
              "      <td>0.993916</td>\n",
              "      <td>0.963543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>embellishment-patches</td>\n",
              "      <td>10</td>\n",
              "      <td>0.989374</td>\n",
              "      <td>0.975711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>embellishment-epaulets</td>\n",
              "      <td>10</td>\n",
              "      <td>0.997722</td>\n",
              "      <td>0.996970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>embellishment-beaded</td>\n",
              "      <td>20</td>\n",
              "      <td>0.998479</td>\n",
              "      <td>0.957529</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      target  best_node  train_accuracy  test_accuracy\n",
              "0               style-modern         20        0.789839       0.694330\n",
              "1       style-businesscasual         30        0.852973       0.756894\n",
              "2              style-classic         20        0.739658       0.653721\n",
              "3               style-casual         20        0.878381       0.755874\n",
              "4          style-androgynous         20        0.867531       0.823800\n",
              "5                 style-boho         20        0.897344       0.880491\n",
              "6                style-retro         30        0.947524       0.943565\n",
              "7                 style-edgy         30        0.831142       0.799285\n",
              "8                 style-glam         20        0.902004       0.891219\n",
              "9             style-romantic         10        0.869318       0.857001\n",
              "10          style-athleisure         10        0.986977       0.952246\n",
              "11             occasion-work         30        0.863631       0.737864\n",
              "12       occasion-daytonight         10        0.761947       0.740918\n",
              "13          occasion-weekend         20        0.809081       0.772094\n",
              "14         occasion-vacation         30        0.879151       0.844406\n",
              "15         occasion-nightout         20        0.832459       0.776697\n",
              "16      occasion-coldweather         30        0.954713       0.934083\n",
              "17          occasion-workout         20        0.983139       0.967550\n",
              "18    embellishment-crystals         30        0.998479       0.966620\n",
              "19        embellishment-mesh         30        0.992395       0.936177\n",
              "20        embellishment-lace         30        0.993156       0.933054\n",
              "21        embellishment-trim         20        0.937677       0.884569\n",
              "22     embellishment-ruffles         10        0.992395       0.884569\n",
              "23      embellishment-fringe         20        0.979491       0.960466\n",
              "24       embellishment-studs         20        0.984791       0.869371\n",
              "25  embellishment-embroidery         20        0.947598       0.884429\n",
              "26     embellishment-buckles         10        0.964302       0.926993\n",
              "27  embellishment-rhinestone         10        0.997719       0.969604\n",
              "28     embellishment-sequins         20        0.993916       0.963543\n",
              "29     embellishment-patches         10        0.989374       0.975711\n",
              "30    embellishment-epaulets         10        0.997722       0.996970\n",
              "31      embellishment-beaded         20        0.998479       0.957529"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72bJZzNwmwP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#result_multiclass.to_csv('/content/drive/My Drive/NLP/result_multiclass.csv')\n",
        "#result_binary.to_csv('/content/drive/My Drive/NLP/result_binary.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3rlUU1LXch5",
        "colab_type": "text"
      },
      "source": [
        "## Implementing the Final Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUTAxXlznCwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#result_multiclass = pd.read_csv('/content/drive/My Drive/NLP/result_multiclass.csv', index_col=0)\n",
        "#result_binary = pd.read_csv('/content/drive/My Drive/NLP/result_binary.csv', index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5VXUT-99gg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Retrain the final model on the whole dataset and then make prediction\n",
        "def implement(padded_docs_input, labelname:str):\n",
        "    '''labelname should be in ['category', 'style', 'occasion', 'embellishment'] '''\n",
        "    data = df.dropna(subset=[labelname]).copy()\n",
        "\n",
        "    if labelname=='category':\n",
        "        encoder = LabelEncoder()\n",
        "        labels = to_categorical(encoder.fit_transform(data[labelname]))\n",
        "        temp = preparemodel(data, embedding_size)\n",
        "        padded_docs_train, vocab_size, max_sequence_len, embedding_matrix = temp[0], temp[1], temp[2], temp[3]\n",
        "        model_multiclass = deepnn_multiclass(padded_docs_train, labels, vocab_size, embedding_size, embedding_matrix, max_sequence_len, node=int(result_multiclass[result_multiclass.target==labelname]['best_node']), val_split=0.1)\n",
        "\n",
        "        score = pd.DataFrame(model_multiclass.predict(padded_docs_input), columns=category_label)\n",
        "        result = score.idxmax(axis=1)\n",
        "        return result\n",
        "    \n",
        "    else:\n",
        "        uniquenames = df.dropna(subset=[labelname])[labelname].unique()\n",
        "\n",
        "        table = pd.DataFrame()\n",
        "        for uniquename in uniquenames:    \n",
        "            data['temp'] = np.where(data[labelname]==uniquename, 0, 1)\n",
        "            data.sort_values(by=['product_id','temp'], inplace=True)\n",
        "            data.drop_duplicates(subset=['product_id'], keep='first', inplace=True)\n",
        "            data.reset_index(drop=True, inplace=True)\n",
        "            labels = np.where(data[labelname]==uniquename,1,0)\n",
        "            temp = preparemodel(data, embedding_size)\n",
        "            padded_docs_train, vocab_size, max_sequence_len, embedding_matrix = temp[0], temp[1], temp[2], temp[3]\n",
        "            model_binary = deepnn_binary(padded_docs_train, labels, vocab_size, embedding_size, embedding_matrix, max_sequence_len, node=int(result_binary[result_binary.target==labelname+'-'+uniquename]['best_node']), val_split=0.1)\n",
        "\n",
        "            score = model_binary.predict(padded_docs_input).flatten()\n",
        "            table[uniquename] = np.where(score>0.5, uniquename,'')\n",
        "        \n",
        "        result = table[uniquenames].agg(' '.join, axis=1)\n",
        "        return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkp_QRmVd_Nq",
        "colab_type": "code",
        "outputId": "da4a78ad-8a12-4017-b44b-95b92d9636b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# subsetting the full_data\n",
        "inputdata = df_SQL[df_SQL.product_id.isin(df.product_id.unique())].reset_index(drop=True)\n",
        "inputdata.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3970, 9)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4541hx3voep",
        "colab_type": "code",
        "outputId": "54957cc2-f4b1-43b3-f3d8-2b4c40f4fb9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# create the columns with predicted label\n",
        "encoder = LabelEncoder()\n",
        "category_label = pd.DataFrame(zip(df.dropna(subset=['category'])['category'], encoder.fit_transform(df.dropna(subset=['category'])['category']))).drop_duplicates()\n",
        "category_label = category_label.sort_values(by=1)[0].tolist()\n",
        "\n",
        "data_clean = preprocessing(inputdata)\n",
        "temp = preparemodel(data_clean, embedding_size)\n",
        "padded_docs, vocab_size, max_sequence_len, embedding_matrix = temp[0], temp[1], temp[2], temp[3]\n",
        "\n",
        "tags = ['category','style','occasion','embellishment']\n",
        "result = pd.DataFrame()\n",
        "for tag in tags:\n",
        "    result[tag] = implement(padded_docs, labelname=tag)\n",
        "    print(f'{tag} is done')\n",
        "\n",
        "#result.to_csv('/content/drive/My Drive/NLP/result.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok\n",
            "category is done\n",
            "style is done\n",
            "occasion is done\n",
            "embellishment is done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twv8dY0M7Vp9",
        "colab_type": "code",
        "outputId": "d661c77c-cac9-4d36-bade-430eb40b6b25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "result"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>style</th>\n",
              "      <th>occasion</th>\n",
              "      <th>embellishment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bottom</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>top</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bottom</td>\n",
              "      <td>modern</td>\n",
              "      <td>work</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>top</td>\n",
              "      <td>modern</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>top</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3965</th>\n",
              "      <td>bottom</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3966</th>\n",
              "      <td>bottom</td>\n",
              "      <td></td>\n",
              "      <td>work</td>\n",
              "      <td>trim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3967</th>\n",
              "      <td>bottom</td>\n",
              "      <td></td>\n",
              "      <td>work</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3968</th>\n",
              "      <td>onepiece</td>\n",
              "      <td></td>\n",
              "      <td>work</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3969</th>\n",
              "      <td>top</td>\n",
              "      <td></td>\n",
              "      <td>work</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3970 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      category             style    occasion      embellishment\n",
              "0       bottom                                                 \n",
              "1          top                                                 \n",
              "2       bottom  modern            work                         \n",
              "3          top  modern                                         \n",
              "4          top                                                 \n",
              "...        ...               ...         ...                ...\n",
              "3965    bottom                                                 \n",
              "3966    bottom                    work           trim          \n",
              "3967    bottom                    work                         \n",
              "3968  onepiece                    work                         \n",
              "3969       top                    work                         \n",
              "\n",
              "[3970 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA0pdEOBjw4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subsetdata = pd.concat([inputdata, result], axis=1, sort=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvo2eryEks2-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "6a124c99-6bd8-4e4e-bcf1-aebf619e1467"
      },
      "source": [
        "#subsetdata.to_csv('/content/drive/My Drive/NLP/subsetdata.csv')\n",
        "subsetdata"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>brand</th>\n",
              "      <th>mpn</th>\n",
              "      <th>product_full_name</th>\n",
              "      <th>description</th>\n",
              "      <th>brand_category</th>\n",
              "      <th>brand_canonical_url</th>\n",
              "      <th>details</th>\n",
              "      <th>labels</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>category</th>\n",
              "      <th>style</th>\n",
              "      <th>occasion</th>\n",
              "      <th>embellishment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01e5zxp5h0btezt9qd2hrzj47a</td>\n",
              "      <td>a.l.c.</td>\n",
              "      <td>5529544</td>\n",
              "      <td>lennox high waist cotton &amp; linen pants</td>\n",
              "      <td>high-rise trousers tailored from a cool italia...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>https://shop.nordstrom.com/s/a-l-c-lennox-high...</td>\n",
              "      <td>true to size. high rise.\\n31\" inseam; 14\" leg ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>bottom</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01dseczpagjjc1edc79jrbf4wk</td>\n",
              "      <td>banana republic</td>\n",
              "      <td>492444</td>\n",
              "      <td>mock-neck sweater top</td>\n",
              "      <td>designed to be worn with high-waisted bottoms,...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>https://bananarepublic.gap.com/browse/product....</td>\n",
              "      <td>designed to be worn with high-waisted bottoms,...</td>\n",
              "      <td>{\"needs review\"}</td>\n",
              "      <td>1</td>\n",
              "      <td>top</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01e607bhrqajdz76mjfn7rprk1</td>\n",
              "      <td>simon miller</td>\n",
              "      <td>5450059</td>\n",
              "      <td>rost belted shorts</td>\n",
              "      <td>cinched at the natural waist and pleated for f...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>https://shop.nordstrom.com/s/simon-miller-rost...</td>\n",
              "      <td>true to size. xs=0-2, s=4-6, m=6-8, l=8-10, xl...</td>\n",
              "      <td>[]</td>\n",
              "      <td>2</td>\n",
              "      <td>bottom</td>\n",
              "      <td>modern</td>\n",
              "      <td>work</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01e5zxj6g03r7177x723ct04w0</td>\n",
              "      <td>a.l.c.</td>\n",
              "      <td>5526479</td>\n",
              "      <td>minelli silk sleeveless top</td>\n",
              "      <td>painterly brushes of color that convey the flu...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>https://shop.nordstrom.com/s/a-l-c-minelli-sil...</td>\n",
              "      <td>true to size.\\n25 1/2\" length (size medium)\\nf...</td>\n",
              "      <td>[{'value': 'unsure'}]</td>\n",
              "      <td>3</td>\n",
              "      <td>top</td>\n",
              "      <td>modern</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01e6074pqa697jz1sbm6nm8tbg</td>\n",
              "      <td>simon miller</td>\n",
              "      <td>5450071</td>\n",
              "      <td>nepa mismatched button rib cardigan</td>\n",
              "      <td>the west coast–based label channels beachy vib...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>https://shop.nordstrom.com/s/simon-miller-nepa...</td>\n",
              "      <td>true to size. xs=0-2, s=4-6, m=6-8, l=8-10, xl...</td>\n",
              "      <td>[]</td>\n",
              "      <td>4</td>\n",
              "      <td>top</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3965</th>\n",
              "      <td>01e2kz045bct1q2z2pbc0cwrgh</td>\n",
              "      <td>atm anthony thomas melillo</td>\n",
              "      <td>5441202</td>\n",
              "      <td>micro twill pull on pants</td>\n",
              "      <td>these casual trousers are cut for an easy, dra...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>https://shop.nordstrom.com/s/atm-anthony-thoma...</td>\n",
              "      <td>true to size. xs=0, s=2-4, m=6-8, l=10. high r...</td>\n",
              "      <td>[]</td>\n",
              "      <td>3965</td>\n",
              "      <td>bottom</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3966</th>\n",
              "      <td>01e2kxz0wnq96s64tdze3wb7cx</td>\n",
              "      <td>atm anthony thomas melillo</td>\n",
              "      <td>5504588</td>\n",
              "      <td>brushed twill crop wide leg pants</td>\n",
              "      <td>brushed twill gives these cropped wide-leg pan...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>https://shop.nordstrom.com/s/atm-anthony-thoma...</td>\n",
              "      <td>true to size. high rise.</td>\n",
              "      <td>[]</td>\n",
              "      <td>3966</td>\n",
              "      <td>bottom</td>\n",
              "      <td></td>\n",
              "      <td>work</td>\n",
              "      <td>trim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3967</th>\n",
              "      <td>01e2kxwwy6jagened7p62090np</td>\n",
              "      <td>atm anthony thomas melillo</td>\n",
              "      <td>4496777</td>\n",
              "      <td>slim crop pants</td>\n",
              "      <td>tailored from a soft, dense knit with cropped,...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>https://shop.nordstrom.com/s/atm-anthony-thoma...</td>\n",
              "      <td>mid rise. true to size.</td>\n",
              "      <td>[]</td>\n",
              "      <td>3967</td>\n",
              "      <td>bottom</td>\n",
              "      <td></td>\n",
              "      <td>work</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3968</th>\n",
              "      <td>01e2kztepe7qk1v8thasf7hwnr</td>\n",
              "      <td>atm anthony thomas melillo</td>\n",
              "      <td>5289605</td>\n",
              "      <td>camo print silk skirt</td>\n",
              "      <td>flatlock-stitched bias seams enhance the fluid...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>https://shop.nordstrom.com/s/atm-anthony-thoma...</td>\n",
              "      <td>true to size. xs=0, s=2-4, m=6-8, l=10.</td>\n",
              "      <td>[]</td>\n",
              "      <td>3968</td>\n",
              "      <td>onepiece</td>\n",
              "      <td></td>\n",
              "      <td>work</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3969</th>\n",
              "      <td>01e2ky2t6yv7r4vxt4bvv4twt5</td>\n",
              "      <td>atm anthony thomas melillo</td>\n",
              "      <td>4788992</td>\n",
              "      <td>stretch pima cotton baby tee</td>\n",
              "      <td>made from atm’s signature peruvian jersey, thi...</td>\n",
              "      <td>unknown</td>\n",
              "      <td>https://shop.nordstrom.com/s/atm-anthony-thoma...</td>\n",
              "      <td>true to size. xs=0, s=2-4, m=6-8, l=10.</td>\n",
              "      <td>[]</td>\n",
              "      <td>3969</td>\n",
              "      <td>top</td>\n",
              "      <td></td>\n",
              "      <td>work</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3970 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      product_id  ...      embellishment\n",
              "0     01e5zxp5h0btezt9qd2hrzj47a  ...                   \n",
              "1     01dseczpagjjc1edc79jrbf4wk  ...                   \n",
              "2     01e607bhrqajdz76mjfn7rprk1  ...                   \n",
              "3     01e5zxj6g03r7177x723ct04w0  ...                   \n",
              "4     01e6074pqa697jz1sbm6nm8tbg  ...                   \n",
              "...                          ...  ...                ...\n",
              "3965  01e2kz045bct1q2z2pbc0cwrgh  ...                   \n",
              "3966  01e2kxz0wnq96s64tdze3wb7cx  ...     trim          \n",
              "3967  01e2kxwwy6jagened7p62090np  ...                   \n",
              "3968  01e2kztepe7qk1v8thasf7hwnr  ...                   \n",
              "3969  01e2ky2t6yv7r4vxt4bvv4twt5  ...                   \n",
              "\n",
              "[3970 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTvVcWy_9dU5",
        "colab_type": "code",
        "outputId": "dc049b78-fbf0-4dac-ecaf-c29e0d5dc2f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "end = pd.datetime.now()\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:32:23.384532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1Eu2lFVW-Jz",
        "colab_type": "text"
      },
      "source": [
        "We had out of vocabular errors, so we just performed predictions on the  subsetted labelled data as professor mentioned in the slack. "
      ]
    }
  ]
}